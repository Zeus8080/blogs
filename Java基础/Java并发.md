## 一、学习路线
![](/图片/并发/Java多线程编程学习体系图.jpg)

## 二、开始学习
### 1.基本概念
#### 1.1线程安全概念
《Java Concurrency In Practice》的作者Brian  Goetz 对"线程安全"有一段定义: 当多个线程访问一个对象的时候, 如果不用考虑这些线程在运行时环境下的调度和交替执行, 也不需要惊醒额外的同步,或者在调用方惊醒任何其他的协调操作,调用这个对象的行为都可以获取正确的结果,那这个对象就是线程安全的. 

##### 1.2线程安全的实现方法
  在写解决方案之前，我们首先要明确，多线程的3个重要特性：<br/>
1.原子性：这一点，跟数据库事务的原子性概念差不多，即一个操作（有可能包含有多个子操作）要么全部执行（生效），要么全部都不执行（都不生效）;一般来说对基本数据类型的变量的读取和赋值是原子操作,不过这里有一点需要注意：在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性<br/>
2.可见性：指的是当一个线程对共享变量的修改，其他线程能够立即看到。（由于cpu从主存读取数据的效率相对而言并不高，所以现在主流的计算机都有几级缓存。每个线程读取共享变量时，都会将该变量加载进其对应CPU的高速缓存里，修改该变量后，CPU会立即更新该缓存，但并不一定会立即将其写回主内存，实际上写回主内存的时间不可预期。此时其它线程< 特别是不在同一个CPU上执行的线程 >访问该变量时，从主内存中读到的就是旧的数据，而非第一个线程更新后的数据。）<br/>
3.顺序性：程序执行的顺序按照代码的先后顺序执行（在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。）<br/>

**线程安全的实现方法**：<br>
1.互斥同步：使用synchronized和锁机制<br>
2.非阻塞同步：基于冲突检测的乐观锁并发策略，简单的理解就是我们先干了再说，如果没有其他线程访问，那么我们的操作就顺利的完成，如果有其他线程访问，并且产生了冲突，那么我们就再来解决冲突，常见的有：(1)volatile变量（提供可见性，不提供原子性）;(2)CAS原子指令，提供可见性和原子性<br>
3.无同步方案：(1)，可重入代码：也叫做纯代码。相对线程安全来说，可以保证线程安全。可以在代码执行过程中中断它，转去执行另一段代码，而在控制权返回后，原来的程序不会出现任何错误；(2)，线程本地存储：如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行，如果能保证，就可以把共享数据的可见范围限定在同一个线程内，这样无需同步也能保证线程之间不出现数据征用问题。<br>

### 2.锁理论
#### 2.1锁分类
##### 2.1.1自旋锁
自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU,自旋锁又分为简单自旋锁，排队自旋锁，CLH锁，MCS锁具体见识链接。<br/>
https://blog.csdn.net/liu88010988/article/details/50799745
##### 2.1.2偏向锁
Java偏向锁(Biased Locking)是Java6引入的一项多线程优化。它通过消除资源无竞争情况下的同步原语，进一步提高了程序的运行性能。<br/>

偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在接下来的运行过程中，该锁没有被其他的线程访问，则持有偏向锁的线程将永远不需要触发同步。
如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会尝试消除它身上的偏向锁，将锁恢复到标准的轻量级锁。
(偏向锁只能在单线程下起作用)<br/>
因此 流程是这样的 偏向锁->轻量级锁->重量级锁<br/>
https://www.cnblogs.com/charlesblc/p/5994162.html<br>

##### 2.1.3 缓存一致性问题
![](/图片/并发/CAS缓存一致性流量.jpg)
上图大概表明了SMP的结构，其意思是所有的CPU会共享一条系统总线（BUS），靠此总线连接主存。每个核都有自己的一级缓存，各核相对于BUS对称分布，因此这种结构称为“对称多处理器”</br>

Core1和Core2可能会同时把主存中某个位置的值Load到自己的L1 Cache中，当Core1在自己的L1 Cache中修改这个位置的值时，会通过总线，使Core2中L1 Cache对应的值“失效”，而Core2一旦发现自己L1 Cache中的值失效（称为Cache命中缺失）则会通过总线从内存中加载该地址最新的值，大家通过总线的来回通信称为“Cache一致性流量”(通过intel的MESI协议实现)，因为总线被设计为固定的“通信能力”，如果Cache一致性流量过大，总线将成为瓶颈。而当Core1和Core2中的值再次一致时，称为“Cache一致性”，从这个层面来说，锁设计的终极目标便是减少Cache一致性流量。<br/>
 
而CAS恰好会导致Cache一致性流量，如果有很多线程都共享同一个对象，当某个Core CAS成功时必然会引起总线风暴，这就是所谓的本地延迟，本质上偏向锁就是为了消除CAS，降低Cache一致性流量<br/>


##### 2.1.4 可重入锁




  



